# app/services/langchain_rag_service.py
import os
import logging
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.schema import Document

logger = logging.getLogger("soulstay.langchain_rag")

class LangChainRAGService:
    def __init__(self, collection_name="soulstay_feedback"):
        """LangChain ê¸°ë°˜ RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        try:
            self.embeddings = OpenAIEmbeddings(openai_api_key=os.getenv("OPENAI_API_KEY"))
            self.vectorstore = Chroma(
                collection_name=collection_name,
                embedding_function=self.embeddings,
                persist_directory="./chroma_langchain"
            )
            self.llm = ChatOpenAI(
                model="gpt-4o-mini",
                temperature=0.3,
                openai_api_key=os.getenv("OPENAI_API_KEY")
            )
            logger.info(f"âœ… LangChain RAG ì´ˆê¸°í™” ì™„ë£Œ â€” collection='{collection_name}'")
        except Exception as e:
            logger.exception(f"âŒ LangChain RAG ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def add_document(self, text: str, metadata: dict = None):
        """ë¬¸ì„œë¥¼ LangChain VectorStoreì— ì¶”ê°€"""
        try:
            # ê¸´ í…ìŠ¤íŠ¸ëŠ” ìë™ ë¶„í• 
            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
            chunks = splitter.split_text(text)
            docs = [Document(page_content=c, metadata=metadata or {}) for c in chunks]
            self.vectorstore.add_documents(docs)
            logger.info(f"ğŸ“š LangChain RAG ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ ({len(chunks)}ê°œ ì²­í¬)")
        except Exception as e:
            logger.exception(f"âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {e}")

    def search(self, query: str, top_k: int = 3):
        """ë²¡í„° ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            retriever = self.vectorstore.as_retriever(search_kwargs={"k": top_k})
            results = retriever.get_relevant_documents(query)
            logger.info(f"ğŸ” ê²€ìƒ‰ ì™„ë£Œ â€” {len(results)}ê°œ ê²°ê³¼")
            return results
        except Exception as e:
            logger.exception(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def ask_with_context(self, query: str, top_k: int = 3):
        """ë¬¸ì„œ ê²€ìƒ‰ + LLM ë‹µë³€ ìƒì„± (RAG ì™„ì„±í˜•)"""
        try:
            retriever = self.vectorstore.as_retriever(search_kwargs={"k": top_k})
            qa_chain = RetrievalQA.from_chain_type(
                llm=self.llm,
                retriever=retriever,
                chain_type="stuff"
            )
            answer = qa_chain.invoke({"query": query})
            logger.info("ğŸ’¬ RAG ì‘ë‹µ ìƒì„± ì™„ë£Œ")
            return answer["result"]
        except Exception as e:
            logger.exception(f"âŒ RAG ì§ˆì˜ ì‹¤íŒ¨: {e}")
            return "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
