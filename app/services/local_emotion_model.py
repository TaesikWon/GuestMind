# app/services/emotion_analyzer.py
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import logging

logger = logging.getLogger("soulstay.emotion")

# âœ… ëª¨ë¸ ê²½ë¡œ ë° ë¼ë²¨ ì •ì˜
MODEL_PATH = "WhitePeak/bert-base-cased-Korean-sentiment"
LABELS = ["ë¶€ì •", "ì¤‘ë¦½", "ê¸ì •"]

# âœ… ëª¨ë¸ & í† í¬ë‚˜ì´ì € ë¡œë“œ (CPU ì „ìš©)
try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
    model.eval()
    logger.info(f"âœ… ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({MODEL_PATH}, CPU ëª¨ë“œ)")
except Exception as e:
    logger.error(f"âŒ ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    tokenizer, model = None, None


def analyze_emotion_local(text: str):
    """
    í•œêµ­ì–´ ê°ì • ë¶„ì„ (CPU ì „ìš©)
    Args:
        text (str): ë¶„ì„í•  ë¬¸ì¥
    Returns:
        dict: {"emotion": ê°ì •ë¼ë²¨, "reason": ë¶„ì„ê²°ê³¼ì„¤ëª…}
    """
    if not text or not text.strip():
        logger.warning("âš ï¸ ê°ì • ë¶„ì„ ì‹¤íŒ¨ â€” ì…ë ¥ì´ ë¹„ì–´ ìˆìŒ")
        return {"emotion": "ì¤‘ë¦½", "reason": "ì…ë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}

    if model is None or tokenizer is None:
        return {"emotion": "ì¤‘ë¦½", "reason": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    try:
        inputs = tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=128
        )

        with torch.no_grad():
            outputs = model(**inputs)
            pred = torch.argmax(outputs.logits, dim=1).item()
            emotion = LABELS[pred]

        logger.info(f"ğŸ§  ê°ì • ë¶„ì„ ê²°ê³¼: '{text[:30]}...' â†’ {emotion}")
        return {"emotion": emotion, "reason": f"Hugging Face ëª¨ë¸({MODEL_PATH}) ì˜ˆì¸¡ ê²°ê³¼"}

    except Exception as e:
        logger.error(f"âŒ ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {"emotion": "ì¤‘ë¦½", "reason": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}
