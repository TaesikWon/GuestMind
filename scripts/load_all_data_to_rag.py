# scripts/load_all_data_to_rag.py
import os, sys, glob, logging, pandas as pd, chardet
from PyPDF2 import PdfReader
from docx import Document  # âœ… DOCX ì½ê¸°ìš©

# âœ… SoulStay ë£¨íŠ¸ ê²½ë¡œ ì¸ì‹ (ê°€ì¥ ì¤‘ìš”)
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from app.services.rag_service import add_feedback_to_rag, get_rag_status

# âœ… ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s - %(message)s",
)
logger = logging.getLogger("soulstay.load_all")

# âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_pdf_text(path: str) -> str:
    try:
        reader = PdfReader(path)
        text = "\n".join([page.extract_text() or "" for page in reader.pages])
        return text.strip()
    except Exception as e:
        logger.error(f"âŒ PDF ì½ê¸° ì‹¤íŒ¨ ({path}): {e}")
        return ""

# âœ… DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_docx_text(path: str) -> str:
    try:
        doc = Document(path)
        text = "\n".join([p.text for p in doc.paragraphs])
        text = text.strip()
        if not text:
            logger.warning(f"âš ï¸ DOCX ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ: {path}")
        return text
    except Exception as e:
        logger.error(f"âŒ DOCX ì½ê¸° ì‹¤íŒ¨ ({path}): {e}")
        return ""

# âœ… PDF + DOCX ë¡œë“œ
def load_docs():
    data_dir = os.path.join("data", "pdfs")
    os.makedirs(data_dir, exist_ok=True)
    files = glob.glob(os.path.join(data_dir, "*.pdf")) + glob.glob(os.path.join(data_dir, "*.docx"))
    if not files:
        logger.warning("âš ï¸ data/pdfs í´ë”ì— PDF/DOCX íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    logger.info(f"ğŸ“‚ {len(files)}ê°œì˜ PDF/DOCX íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    count = 0
    for path in files:
        ext = os.path.splitext(path)[1].lower()
        text = extract_pdf_text(path) if ext == ".pdf" else extract_docx_text(path)
        if not text:
            continue
        base_name = os.path.basename(path)
        add_feedback_to_rag(user_id=0, feedback_text=text)
        logger.info(f"âœ… '{base_name}' ë“±ë¡ ì™„ë£Œ")
        count += 1
    return count

# âœ… CSV ì¸ì½”ë”© ê°ì§€
def read_csv_safely(csv_path):
    try:
        return pd.read_csv(csv_path, encoding="utf-8")
    except UnicodeDecodeError:
        try:
            return pd.read_csv(csv_path, encoding="cp949")
        except UnicodeDecodeError:
            with open(csv_path, "rb") as f:
                raw_data = f.read(50000)
                detected = chardet.detect(raw_data)
                enc = detected.get("encoding", "utf-8")
                logger.warning(f"âš ï¸ ì¸ì½”ë”© ê°ì§€ë¨: {enc} ({os.path.basename(csv_path)})")
                return pd.read_csv(csv_path, encoding=enc)

# âœ… CSV ë¡œë“œ
def load_csvs():
    csv_dir = os.path.join("data", "hotel")
    os.makedirs(csv_dir, exist_ok=True)
    csv_files = glob.glob(os.path.join(csv_dir, "*.csv"))
    if not csv_files:
        logger.warning("âš ï¸ data/hotel í´ë”ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    logger.info(f"ğŸ“Š {len(csv_files)}ê°œì˜ CSV íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    count = 0
    for csv_path in csv_files:
        try:
            df = read_csv_safely(csv_path)
            text = df.to_string(index=False)
            base_name = os.path.basename(csv_path)
            add_feedback_to_rag(user_id=0, feedback_text=text)
            logger.info(f"âœ… '{base_name}' ë“±ë¡ ì™„ë£Œ")
            count += 1
        except Exception as e:
            logger.error(f"âŒ '{csv_path}' ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    return count

# âœ… ì „ì²´ ì‹¤í–‰
def main():
    logger.info("ğŸš€ RAG ë°ì´í„° í†µí•© ë“±ë¡ ì‹œì‘ (PDF + DOCX + CSV)")
    total_docs = load_docs()
    total_csvs = load_csvs()
    status = get_rag_status()
    logger.info(f"ğŸ“¦ ì´ {total_docs}ê°œ ë¬¸ì„œ(PDF/DOCX), {total_csvs}ê°œ CSV ë“±ë¡ ì™„ë£Œ")
    logger.info(f"ğŸ“Š í˜„ì¬ RAG ë¬¸ì„œ ì´ {status.get('total_documents', '?')}ê°œ")
    logger.info("ğŸ ëª¨ë“  ë°ì´í„° ë“±ë¡ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
