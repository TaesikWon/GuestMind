# train_emotion_model.py

from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import os

# âœ… 1. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°
model_name = "monologg/koelectra-base-v3-discriminator"
tokenizer = AutoTokenizer.from_pretrained(model_name)

# âœ… 2. ë°ì´í„°ì…‹ ë¡œë“œ
dataset = load_dataset("csv", data_files={"train": "data/train.csv", "test": "data/test.csv"})

# âœ… 3. í† í¬ë‚˜ì´ì§•
def tokenize(batch):
    return tokenizer(batch["text"], truncation=True, padding="max_length", max_length=128)
dataset = dataset.map(tokenize, batched=True)

# âœ… 4. ë¼ë²¨ ì¸ì½”ë”©
labels = {"positive": 0, "negative": 1, "neutral": 2}
def encode_labels(example):
    example["labels"] = labels[example["label"]]
    return example
dataset = dataset.map(encode_labels)

# âœ… 5. í¬ë§· ì„¤ì • (PyTorch í…ì„œë¡œ ë³€í™˜)
dataset.set_format(type="torch", columns=["input_ids", "attention_mask", "labels"])

# âœ… 6. ëª¨ë¸ ì •ì˜
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)

# âœ… 7. í‰ê°€ í•¨ìˆ˜ ì •ì˜
def compute_metrics(pred):
    preds = pred.predictions.argmax(-1)
    labels = pred.label_ids
    acc = accuracy_score(labels, preds)
    f1 = f1_score(labels, preds, average="weighted")
    return {"accuracy": acc, "f1": f1}

# âœ… 8. í•™ìŠµ ì„¤ì •
training_args = TrainingArguments(
    output_dir="models/emotion_classifier",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    num_train_epochs=3,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,  # ì¶”ê°€
    learning_rate=2e-5,  # ì¶”ê°€
    weight_decay=0.01,  # ì¶”ê°€
    warmup_steps=100,  # ì¶”ê°€
    load_best_model_at_end=True,
    metric_for_best_model="f1",  # ì¶”ê°€
    logging_dir="logs",
    logging_steps=50,  # 100 â†’ 50 (ë” ìì£¼ ë¡œê¹…)
    save_total_limit=2,  # ì¶”ê°€ (ìµœê·¼ 2ê°œ ì²´í¬í¬ì¸íŠ¸ë§Œ ì €ì¥)
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)

# âœ… 9. í•™ìŠµ ë° ì €ì¥
print("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
trainer.train()

# ì €ì¥ ê²½ë¡œ ìƒì„±
os.makedirs("models/emotion_classifier", exist_ok=True)
model.save_pretrained("models/emotion_classifier")
tokenizer.save_pretrained("models/emotion_classifier")
print("âœ… ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ")

# âœ… 10. í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€
print("\nğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€ ì¤‘...")
predictions = trainer.predict(dataset["test"])
pred_labels = predictions.predictions.argmax(-1)
true_labels = predictions.label_ids

print("\nğŸ“ˆ Classification Report:")
print(classification_report(true_labels, pred_labels, target_names=list(labels.keys())))

# âœ… 11. í˜¼ë™í–‰ë ¬ ì‹œê°í™”
cm = confusion_matrix(true_labels, pred_labels)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=list(labels.keys()), yticklabels=list(labels.keys()))
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Emotion Classification Confusion Matrix")
plt.tight_layout()

# ì €ì¥ ê²½ë¡œ ìƒì„±
os.makedirs("models", exist_ok=True)
plt.savefig("models/confusion_matrix.png", dpi=300, bbox_inches='tight')
print("âœ… Confusion Matrix ì €ì¥ ì™„ë£Œ: models/confusion_matrix.png")
plt.show()